import argparse
import json
import csv
from pathlib import Path
from typing import List, Dict, Any


def flatten_sample_metrics(
    sample: Dict[str, Any], num_classes: int, model_type: str, cam_type: str
) -> Dict[str, Any]:
    """
    Flattens the nested metrics of a single sample into a flat dictionary.
    """
    flat_row = {
        "model_type": model_type,
        "cam_type": cam_type,
        "sample_index": sample.get("index"),
        "selected_cam_class": sample.get("selected_cam_class"),
        "cam_branch": sample.get("cam_branch"),
    }

    # --- Flatten Segmentation Metrics ---
    seg_metrics = sample.get("metrics", {}).get("segmentation", {})
    if seg_metrics:
        flat_row["dice_mean"] = seg_metrics.get("dice_mean")
        flat_row["iou_mean"] = seg_metrics.get("iou_mean")

        dice_per_class = seg_metrics.get("dice_per_class", [])
        for i in range(num_classes):
            flat_row[f"dice_class_{i}"] = dice_per_class[i] if i < len(dice_per_class) else None

        iou_per_class = seg_metrics.get("iou_per_class", [])
        for i in range(num_classes):
            flat_row[f"iou_class_{i}"] = iou_per_class[i] if i < len(iou_per_class) else None

    # --- Flatten Information Loss Metrics ---
    info_loss_metrics = sample.get("metrics", {}).get("information_loss", {})
    if info_loss_metrics:
        flat_row["info_loss_weighted_mean"] = info_loss_metrics.get("weighted_loss")
        flat_row["info_loss_unweighted_mean"] = info_loss_metrics.get("mean_loss")
        flat_row["info_increase_weighted_mean"] = info_loss_metrics.get("increase_weighted")
        flat_row["info_increase_unweighted_mean"] = info_loss_metrics.get("increase_mean")

        loss_per_class = info_loss_metrics.get("loss_per_class", [])
        class_loss_map = {entry["class_id"]: entry for entry in loss_per_class}

        for i in range(num_classes):
            class_entry = class_loss_map.get(i)
            if class_entry:
                flat_row[f"info_loss_class_{i}"] = class_entry.get("loss")
                flat_row[f"info_loss_pixels_class_{i}"] = class_entry.get("pixels")
                flat_row[f"info_loss_original_conf_class_{i}"] = class_entry.get("original_confidence")
                flat_row[f"info_loss_explainable_conf_class_{i}"] = class_entry.get("explainable_confidence")
                flat_row[f"info_increase_conf_class_{i}"] = class_entry.get("increase_confidence")
                flat_row[f"info_increase_pixels_class_{i}"] = class_entry.get("increase_positive_pixels")
            else:
                flat_row[f"info_loss_class_{i}"] = None
                flat_row[f"info_loss_pixels_class_{i}"] = None
                flat_row[f"info_loss_original_conf_class_{i}"] = None
                flat_row[f"info_loss_explainable_conf_class_{i}"] = None
                flat_row[f"info_increase_conf_class_{i}"] = None
                flat_row[f"info_increase_pixels_class_{i}"] = None

    return flat_row


def get_fieldnames(flat_rows: List[Dict[str, Any]]) -> List[str]:
    """
    Gets a sorted, unique list of all fieldnames from the flattened rows.
    """
    if not flat_rows:
        return []
    
    # Use a set to collect all unique keys
    field_set = set()
    for row in flat_rows:
        field_set.update(row.keys())
        
    # Define a preferred order for clarity
    preferred_order = [
        "sample_index", "selected_cam_class", "cam_branch",
        "dice_mean", "iou_mean",
        "info_loss_weighted_mean", "info_loss_unweighted_mean",
        "info_increase_weighted_mean", "info_increase_unweighted_mean",
    ]
    
    # Separate into ordered and the rest
    ordered_fields = [f for f in preferred_order if f in field_set]
    remaining_fields = sorted([f for f in field_set if f not in ordered_fields])
    
    return ordered_fields + remaining_fields


def main():
    parser = argparse.ArgumentParser(
        description="Tabulate aggregated Seg-CAM metrics from a JSON file into a CSV.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "--input-json",
        type=Path,
        required=True,
        help="Path to the input JSON file generated by compute_segcam_metrics_batch.py."
    )
    parser.add_argument(
        "--output-csv",
        type=Path,
        required=True,
        help="Path to the destination CSV file."
    )
    args = parser.parse_args()

    if not args.input_json.exists():
        print(f"Error: Input file not found at '{args.input_json}'")
        return

    print(f"Reading metrics from: {args.input_json}")
    with open(args.input_json, "r", encoding="utf-8") as f:
        data = json.load(f)

    # Extraer metadatos del nivel superior del JSON
    model_type = data.get("model_type", "unknown")
    cam_type = data.get("cam_type", "unknown")

    samples = data.get("samples")
    if not samples:
        print("Error: No 'samples' key found in the JSON file.")
        return

    # Infer number of classes from the summary if possible, otherwise from the first sample.
    try:
        num_classes = len(data["summary"]["segmentation"]["dice_per_class_mean"])
    except (KeyError, TypeError):
        try:
            num_classes = len(samples[0]["metrics"]["segmentation"]["dice_per_class"])
        except (KeyError, IndexError):
            print("Warning: Could not reliably determine number of classes. Defaulting to 3.")
            num_classes = 3

    # Process all samples into flat rows
    flattened_data = [flatten_sample_metrics(s, num_classes, model_type, cam_type) for s in samples]

    if not flattened_data:
        print("No sample data to write.")
        return

    # Create parent directory for CSV if it doesn't exist
    args.output_csv.parent.mkdir(parents=True, exist_ok=True)

    # Get headers and write to CSV
    fieldnames = get_fieldnames(flattened_data)
    
    print(f"Writing {len(flattened_data)} samples to: {args.output_csv}")
    with open(args.output_csv, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(flattened_data)

    print("CSV file successfully created.")


if __name__ == "__main__":
    main()
